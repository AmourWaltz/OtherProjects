import sysimport timeimport mathimport numpy as npimport pandas as pdimport torchimport torch.tensorimport torch.nn as nnimport torch.optim as optimimport torch.nn.functional as funcfrom torch.utils.data import Dataset, DataLoaderimport matplotlib.pyplot as pltfile_Path = '/Users/collcertaye/WorkSpace/Lab-FECG/FECG_2013DB/dataset/'data_Path = '/Users/collcertaye/WorkSpace/Lab-FECG/FECG_2013DB/dataset_make/'save_Path = '/Users/collcertaye/WorkSpace/Lab-FECG/FECG_2013DB/output_sequence/'# read the FECG data and labelclass SignalDataset(Dataset):    def __init__(self, data, label):        self.data, self.label = data, label    def __getitem__(self, index):        return self.data[index], self.label[index]    def __len__(self):        return len(self.data)# create the lstm modelclass LstmModel(nn.Module):    def __init__(self, input_size, hidden_size, output_size, bidirection=False):        super(LstmModel, self).__init__()        self.lstm = nn.LSTM(input_size=input_size,                            hidden_size=hidden_size,                            num_layers=1,                            batch_first=True,                            bidirectional=bidirection                            )        if bidirection:            self.fcn = nn.Linear(in_features=hidden_size * segment_Length * 2, out_features=output_size)            pass        else:            self.fcn = nn.Linear(in_features=hidden_size * segment_Length, out_features=output_size)            pass        pass    def forward(self, x):        # print(x.shape)        x = x.permute(0, 2, 1)        # print(x.shape)        hidden, _ = self.lstm(x.float())        # print(hidden.shape)        out1 = hidden.reshape(hidden.size(0), -1)        out2 = self.fcn(out1)        # print(out2.shape)        return out2# create uni-demonsion residual blockclass ResidualBlock(nn.Module):    def __init__(self, input_channel, output_channel, stride=1):        super(ResidualBlock, self).__init__()        self.left = nn.Sequential(            nn.Conv1d(in_channels=input_channel,                      out_channels=output_channel,                      kernel_size=3,                      stride=stride,                      padding=1,                      bias=False),            nn.BatchNorm1d(output_channel),            nn.ReLU(inplace=True),            nn.Conv1d(in_channels=output_channel,                      out_channels=output_channel,                      kernel_size=3,                      stride=1,                      padding=1,                      bias=False),            nn.BatchNorm1d(output_channel)        )        self.shortcut = nn.Sequential()        if stride != 1 or input_channel != output_channel:            self.shortcut = nn.Sequential(                nn.Conv1d(in_channels=input_channel,                          out_channels=output_channel,                          kernel_size=1,                          stride=stride,                          bias=False),                nn.BatchNorm1d(output_channel)            )            pass        pass    def forward(self, x):        out = self.left(x)        # print(x.shape)        # print(out.shape)        out += self.shortcut(x)        out = func.relu(out)        return out# create uni-demonsion ResNet-18class UdResNetModel(nn.Module):    def __init__(self, residual_block, output_size):        super(UdResNetModel, self).__init__()        self.inchannel = 64        self.conv1 = nn.Sequential(            nn.Conv1d(in_channels=1,                      out_channels=64,                      kernel_size=3,                      stride=1,                      padding=1,                      bias=False),            nn.BatchNorm1d(64),            nn.ReLU(),        )        self.layer1 = self.make_layer(residual_block, 64,  2, stride=1)        self.layer2 = self.make_layer(residual_block, 128, 2, stride=2)        self.layer3 = self.make_layer(residual_block, 256, 2, stride=2)        self.layer4 = self.make_layer(residual_block, 512, 2, stride=2)        self.fcn = nn.Linear(in_features=5120, out_features=output_size)    def make_layer(self, block, channels, num_blocks, stride):        strides = [stride] + [1] * (num_blocks - 1)        layers = []        for stride in strides:            layers.append(block(self.inchannel, channels, stride))            self.inchannel = channels            pass        return nn.Sequential(*layers)    def forward(self, x):        out = self.conv1(x.float())        out = self.layer1(out)        out = self.layer2(out)        out = self.layer3(out)        out = self.layer4(out)        out = func.avg_pool1d(out, 4)        out = out.view(out.size(0), -1)        out = self.fcn(out)        return out# create unique demonsion AlexCNN modelclass UdAlexCnnModel(nn.Module):    def __init__(self, output_size):        super(UdAlexCnnModel, self).__init__()        self.conv1 = nn.Sequential(            nn.Conv1d(in_channels=1,                      out_channels=96,                      kernel_size=11,                      stride=3                      ),            nn.BatchNorm1d(96),            nn.ReLU(),            nn.MaxPool1d(kernel_size=3, stride=2)        )        self.conv2 = nn.Sequential(            nn.Conv1d(in_channels=96,                      out_channels=256,                      kernel_size=5,                      padding=2                      ),            nn.BatchNorm1d(256),            nn.ReLU(),            nn.MaxPool1d(kernel_size=3, stride=2)        )        self.conv3 = nn.Sequential(            nn.Conv1d(in_channels=256,                      out_channels=384,                      kernel_size=3                      ),            nn.BatchNorm1d(384),            nn.ReLU(),        )        self.conv4 = nn.Sequential(            nn.Conv1d(in_channels=384,                      out_channels=384,                      kernel_size=3                      ),            nn.BatchNorm1d(384),            nn.ReLU(),        )        self.conv5 = nn.Sequential(            nn.Conv1d(in_channels=384,                      out_channels=256,                      kernel_size=3                      ),            nn.BatchNorm1d(256),            nn.ReLU(),            nn.MaxPool1d(kernel_size=3, stride=2)        )        self.fcn = nn.Linear(in_features=2304, out_features=output_size)    def forward(self, x):        # print(x.dtype)        # print(x.shape)        out = self.conv1(x.float())        out = self.conv2(out)        out = self.conv3(out)        out = self.conv4(out)        out = self.conv5(out)        # print(out2.shape)        out = out.view(out.size(0), -1)        # print(out3.shape)        out = self.fcn(out)        # print(out.shape)        return out# locate and return QRS signal segment# normal fetal heart-rate ranges from 100 to 200 (beats/min)def signal_interception(file_name, signal_channel):    dataset_lead = pd.read_csv(file_Path + file_name + '_lead.csv')    dataset_annotation = pd.read_csv(file_Path + file_name + '_ann.csv')    signal_lead = signal_judgement(signal_channel, dataset_lead)    # remove abnormal heart beat id    annotation_id = dataset_annotation['ann_id']    annotation_type = dataset_annotation['ann_type']    annotation_id = list(annotation_id.values)    # 1.7 test: too many features from 75 patients make it difficult to learn, although cut down the samples    # annotation_id = annotation_id[1:30]    # print(len(anns_id))    signal_lead = list(signal_lead.values)    # denoise signal_lead    # signal_lead = wavelet_denoise(signal_lead)    # print(anns_id, anns_type)    cut_num = 0    for loop_i, ann_type in enumerate(list(annotation_type)):        if ann_type != 'N':            annotation_id.pop(loop_i - cut_num)            cut_num += 1            pass        else:            pass        pass    pass    # print(len(anns_id))    # total_normal = (anns_type == 'N').sum()    # print(total_normal)    # length of segments is (sample frequency / heart-rate * 60)    segment_length = round(0.8 * 60 * sample_Frequency / 150)    forward_length = round(0.5 * segment_length)    backward_length = round(0.5 * segment_length)    heartbeat_make = np.zeros((1, segment_length))    heartbeat_id = []    # print(forward_length + backward_length)    for loop_i, qrs_id in enumerate(annotation_id):        if forward_length <= qrs_id <= len(signal_lead) - backward_length:            signal_list = signal_lead[qrs_id - forward_length:qrs_id + backward_length]            signal_segment = torch.tensor(signal_list).unsqueeze(dim=0)            if np.all(heartbeat_make == 0):                heartbeat_make[0, :] = signal_segment                pass            else:                heartbeat_make = np.concatenate((heartbeat_make, signal_segment), axis=0)                pass            heartbeat_id.append(qrs_id)            # if heartbeat_make.shape[0] % 100 == 0:            #     print(heartbeat_make.shape)            #     pass            pass        elif qrs_id < forward_length:            # print("\n first QRS wave lose !")            pass        else:            # print("\n last QRS wave lose !")            pass        pass    pass    # heart-beat figure    # plt.figure()    # plt.plot(dataset_make[0, :])    # plt.title("QRS wave segment")    # plt.show()    comparison_make = comparison_interception(signal_lead, annotation_id, segment_length)    print('\n complete data make' +          '\n heartbeat.shape: ' + str(heartbeat_make.shape) +          '\n comparison.shape: ' + str(comparison_make.shape))    pass    return heartbeat_make, heartbeat_id, comparison_make# comparison dataset from the same signal leaddef comparison_interception(signal_lead, dataset_id, segment_length):    signal_length = len(signal_lead)    beat_nums = len(dataset_id)    comparison_id = []    comparison_make = np.zeros((1, segment_length))    # cut 1.1 times beat_nums comparison segment with judgement    for loop_i in range(round(3.0 * beat_nums)):        random_id = round(np.random.uniform(0, signal_length))        while comparison_judge(random_id, dataset_id, segment_length):            random_id = round(np.random.uniform(0, signal_length))            pass        comparison_id.append(random_id)        pass    pass    # make comparison dataset with the same length as segment_length    forward_length = round(0.5 * segment_length)    backward_length = round(0.5 * segment_length)    for loop_j, random_id in enumerate(comparison_id):        if forward_length <= random_id <= len(signal_lead) - backward_length:            random_list = signal_lead[random_id - forward_length:random_id + backward_length]            random_segment = torch.tensor(random_list).unsqueeze(dim=0)            if np.all(comparison_make == 0):                comparison_make[0, :] = random_segment                pass            else:                comparison_make = np.concatenate((comparison_make, random_segment), axis=0)                pass            # if comparison_make.shape[0] % 100 == 0:            #     print(comparison_make.shape)            #     pass            pass        else:            # print("\n comparison interception lose !")            pass        pass    pass    return comparison_make# judge the comparison centre that isn't closed to any qrs_iddef comparison_judge(random_id, dataset_id, segment_length):    forward_length = round(0.3 * segment_length)    backward_length = round(0.3 * segment_length)    for qrs_id in dataset_id:        if qrs_id - forward_length <= random_id <= qrs_id + backward_length:            return True    return False# make and save the dataset by rule# .csv dataset format: [0:segment_length]: signal_segment;# [segment_length]: qrs_id(if not comparison, else 0); [segment_length]: labeldef maker_and_saver(file_name, signal_channel):    dataset_make, dataset_id, comparison_make = signal_interception(file_name, signal_channel)    # contain the comparison id 0, and label 0    comparison_id = np.zeros((comparison_make.shape[0], 2))    comparison_set = np.concatenate((comparison_make, comparison_id), axis=1)    # define the qrs segment label as 1    dataset_id = torch.tensor(dataset_id).unsqueeze(dim=1)    dataset_make = np.concatenate((dataset_make, dataset_id), axis=1)    dataset_label = np.ones((dataset_make.shape[0], 1))    heartbeat_set = np.concatenate((dataset_make, dataset_label), axis=1)    # save as .csv file    heartbeat_set = pd.DataFrame(heartbeat_set)    comparison_set = pd.DataFrame(comparison_set)    heartbeat_set.to_csv(data_Path + str(signal_Channel) + '/' + file_name + '_heartbeat.csv', index=False)    comparison_set.to_csv(data_Path + str(signal_Channel) + '/' + file_name + '_comparison.csv', index=False)    # print("\n heartbeat.shape: " + str(heartbeat_set.shape) +    #       "\n comparison.shape: " + str(comparison_set.shape))# get file name num_start - num_enddef name_list(num_start, num_end):    file_name = []    file_list = range(num_start - 1, num_end)    for loop_i in file_list:        if loop_i < 9:            file_read = 'a0' + str(loop_i + 1)            pass        else:            file_read = 'a' + str(loop_i + 1)        # print("file_name: " + file_read)        file_name.append(file_read)        pass    pass    return file_name# save all files as .csv filedef save_all_file():    file_list = name_list(1, 10)    for file_name in file_list:        maker_and_saver(file_name, signal_Channel)        pass    pass    print("\n complete dataset save !")# load all files and storage the data# mix the data from different patients and train a mixed framedef file_loader(start_seq, end_seq):    file_list = name_list(start_seq, end_seq)    heartbeat_set = None    comparison_set = None    for loop_i, file_name in enumerate(file_list):        heartbeat_read = pd.read_csv(data_Path + str(signal_Channel) + '/' + file_name + '_heartbeat.csv')        comparison_read = pd.read_csv(data_Path + str(signal_Channel) + '/' + file_name + '_comparison.csv')        heartbeat_read = heartbeat_read.values[:, :]        comparison_read = comparison_read.values[:, :]        if loop_i == 0:            heartbeat_set = heartbeat_read            comparison_set = comparison_read            pass        else:            heartbeat_set = np.concatenate((heartbeat_set, heartbeat_read), axis=0)            comparison_set = np.concatenate((comparison_set, comparison_read), axis=0)            pass        # print(heartbeat_set)        # print(heartbeat_set.shape)        # print(comparison_set)        # print(comparison_set.shape)        pass    pass    print(' complete dataset make !' +          '\n heartbeat.shape: ' + str(heartbeat_set.shape) +          '\n comparison.shape: ' + str(comparison_set.shape))    pass    return heartbeat_set, comparison_set# load the dataset and sort in random：Intra-Patientdef intra_dataset_loader():    # divide the trainset:valset:testset into the proportion 11:1:3 approximately    heartbeat_set, comparison_set = file_loader(1, 10)    np.random.shuffle(heartbeat_set)    heartbeat_train = heartbeat_set[:round(0.76 * heartbeat_set.shape[0]), :]    heartbeat_val = heartbeat_set[round(0.76 * heartbeat_set.shape[0]):round(0.83 * heartbeat_set.shape[0]), :]    heartbeat_test = heartbeat_set[round(0.84 * heartbeat_set.shape[0]):, :]    # print("heartbeat: train: " + str(heartbeat_train.shape) + " val: " + str(heartbeat_val.shape) +    #       " test: " + str(heartbeat_test.shape))    np.random.shuffle(comparison_set)    comparison_train = comparison_set[:round(0.76 * comparison_set.shape[0]), :]    comparison_val = comparison_set[round(0.76 * comparison_set.shape[0]):round(0.83 * comparison_set.shape[0]), :]    comparison_test = comparison_set[round(0.83 * comparison_set.shape[0]):, :]    # print("comparison: train: " + str(comparison_train.shape) + " val: " + str(comparison_set.shape) +    #       " test: " + str(comparison_test.shape))    # make sure that the order in random    signal_train = np.concatenate((heartbeat_train, comparison_train), axis=0)    signal_val = np.concatenate((heartbeat_val, comparison_val), axis=0)    signal_test = np.concatenate((heartbeat_test, comparison_test), axis=0)    np.random.shuffle(signal_train)    np.random.shuffle(signal_val)    np.random.shuffle(signal_test)    # print(signal_train[:, :-1], signal_test[:, :-1])    # print(signal_train[:, -1], signal_test[:, -1])    train_maker = SignalDataset(signal_train[:, :-1], signal_train[:, -1])    val_maker = SignalDataset(signal_val[:, :-1], signal_val[:, -1])    test_maker = SignalDataset(signal_test[:, :-1], signal_test[:, -1])    train_dataset = DataLoader(train_maker, 12, shuffle=True, num_workers=4)    val_dataset = DataLoader(val_maker, 12, shuffle=True, num_workers=4)    test_dataset = DataLoader(test_maker, 12, shuffle=True, num_workers=4)    print('\n complete dataset load !' +          '\n trainset.length: ' + str(len(train_maker)) + ' trainbatch.length: ' + str(len(train_dataset)) +          '\n valset.length: ' + str(len(val_maker)) + ' valbatch.length: ' + str(len(val_dataset)) +          '\n testset.length: ' + str(len(test_maker)) + ' testbatch.length: ' + str(len(test_dataset)))    pass    return train_dataset, val_dataset, test_dataset# load the dataset and sort in random：Inter-Patientdef inter_dataset_loader():    print("\n trainset: ")    heartbeat_train, comparison_train = file_loader(1, 10)    print("\n valset: ")    heartbeat_val, comparison_val = file_loader(11, 12)    print("\n testset: ")    heartbeat_test, comparison_test = file_loader(13, 20)    # make sure that the order in random    signal_train = np.concatenate((heartbeat_train, comparison_train), axis=0)    signal_val = np.concatenate((heartbeat_val, comparison_val), axis=0)    signal_test = np.concatenate((heartbeat_test, comparison_test), axis=0)    np.random.shuffle(signal_train)    np.random.shuffle(signal_val)    np.random.shuffle(signal_test)    train_maker = SignalDataset(signal_train[:, :-1], signal_train[:, -1])    val_maker = SignalDataset(signal_val[:, :-1], signal_val[:, -1])    test_maker = SignalDataset(signal_test[:, :-1], signal_test[:, -1])    train_dataset = DataLoader(train_maker, 12, shuffle=True, num_workers=4)    val_dataset = DataLoader(val_maker, 12, shuffle=True, num_workers=4)    test_dataset = DataLoader(test_maker, 12, shuffle=True, num_workers=4)    print('\n complete dataset load !' +          '\n trainset.length: ' + str(len(train_maker)) + ' trainbatch.length: ' + str(len(train_dataset)) +          '\n valset.length: ' + str(len(val_maker)) + ' valbatch.length: ' + str(len(val_dataset)) +          '\n testset.length: ' + str(len(test_maker)) + ' testbatch.length: ' + str(len(test_dataset)))    pass    return train_dataset, val_dataset, test_dataset# false positive and false negative calculationdef false_positive_negative(prediction, label):    false_positive = 0    false_negative = 0    all_positive = list(label).count(1)    all_negative = list(label).count(0)    for index, pre_value in enumerate(prediction):        if label[index] != pre_value and label[index] == 1:            false_negative += 1            pass        elif label[index] != pre_value and label[index] == 0:            false_positive += 1            pass        else:            pass        pass    # print(all_positive, all_negative, false_positive, false_negative)    return all_positive, all_negative, false_positive, false_negative# train and test processdef trainer_and_test(model, epoch_num):    train_ls, val_ls = [], []    train_loader, val_loader, test_loader = intra_dataset_loader()    for epoch in range(epoch_num):        # train process        train_accuracy = 0        current_loss = 0        circle_sample = 0        positive_all = 0        negative_all = 0        fpositive_all = 0        fnegative_all = 0        for train_data, train_label in train_loader:            # expect the train_data.shape as (batch_size, feature_vector=in_channels, sequence_length)            train_data = torch.unsqueeze(train_data[:, :-1], dim=1)            # print(train_data.shape, train_label.shape)            optimizer.zero_grad()            # print(train_data.dtype)            train_output = model(train_data)            # print(train_output.shape)            train_loss = criterion(train_output, train_label.long())            # print(" train_loss: ", train_loss)            # print(torch.argmax(train_output, dim=1), train_label)            prediction = torch.argmax(train_output, dim=1)            train_accuracy += (prediction == train_label).sum().float()            circle_sample += len(train_label)            train_loss.backward()            optimizer.step()            current_loss += train_loss            # print(" train_acc:", train_accuracy / circle_sample)            positive_num, negative_num, fpositive_num, fnegative_num = false_positive_negative(prediction, train_label)            positive_all += positive_num            negative_all += negative_num            fpositive_all += fpositive_num            fnegative_all += fnegative_num            pass        train_ls.append(current_loss / len(train_loader))        pass        print("\n epoch: ", epoch, " \n train_loss: ", train_ls[-1], " train_acc: ", train_accuracy / circle_sample)        print(" false_positive_rate: %.4f, false_negative_rate: %.4f"              % (fpositive_all / positive_all, fnegative_all / negative_all))        # verify process        current_loss = 0        circle_sample = 0        val_accuracy = 0        for val_data, val_label in val_loader:            # the same step as train_data            val_data = torch.unsqueeze(val_data[:, :-1], dim=1)            val_output = model(val_data)            val_loss = criterion(val_output, val_label.long())            # print(torch.argmax(val_output, dim=1), val_label)            prediction = torch.argmax(val_output, dim=1)            val_accuracy += (prediction == val_label).sum().float()            circle_sample += len(val_label)            current_loss += val_loss            pass        val_ls.append(current_loss / len(val_loader))        pass        print(" val_loss: ", val_ls[-1], " val_acc: ", val_accuracy / circle_sample)    pass    # test process    current_loss = 0    test_accuracy = 0    circle_sample = 0    positive_all = 0    negative_all = 0    fpositive_all = 0    fnegative_all = 0    for test_data, test_label in test_loader:        # the same step as before        test_data = torch.unsqueeze(test_data[:, :-1], dim=1)        # print(test_data.shape)        test_output = model(test_data)        test_loss = criterion(test_output, test_label.long())        # print("\n test_loss: ", test_loss)        # print(torch.argmax(test_output, dim=1), test_label)        prediction = torch.argmax(test_output, dim=1)        test_accuracy += (prediction == test_label).sum().float()        circle_sample += len(test_label)        current_loss += test_loss        positive_num, negative_num, fpositive_num, fnegative_num = false_positive_negative(prediction, test_label)        positive_all += positive_num        negative_all += negative_num        fpositive_all += fpositive_num        fnegative_all += fnegative_num        pass    test_ls = current_loss / len(test_loader)    pass    print("\n test_loss: ", test_ls, " test_acc: ", test_accuracy / circle_sample)    print(" false_positive_rate: %.4f, false_negative_rate: %.4f"          % (fpositive_all / positive_all, fnegative_all / negative_all))    print("\n train and test process complete ! \n")    return train_ls, val_ls, test_ls, model# sliding window detect heart-beat by QRS wavedef slide_detection(file_name, signal_channel, model):    dataset_lead = pd.read_csv(file_Path + file_name + '_lead.csv')    signal_lead = signal_judgement(signal_channel, dataset_lead)    # slide the model onto the signal_lead and return a sequence that QRS wave exist    signal_lead = list(signal_lead.values)    segment_length = round(0.8 * 60 * sample_Frequency / 150)    print_every = 20000    output_sequence = []    for loop_i in range(len(signal_lead) - segment_length):        signal_segment = signal_lead[loop_i:loop_i + segment_length]        signal_segment = torch.tensor(signal_segment).unsqueeze(dim=0)        # print(signal_segment.unsqueeze(dim=0).shape)        if loop_i % print_every == 0:            print("sliding process: ", loop_i)            # print("sequence: ", output_sequence)            pass        segment_output = model(signal_segment.unsqueeze(dim=0))        # construct softmax function that return the QRS point possibility        segment_output = segment_output.detach().numpy()        score_sequence = np.exp(segment_output[:, 1]) / np.sum(np.exp(segment_output))        output_sequence.append(score_sequence)        pass    pass    # print(output_sequence)    # output_sequence = pd.DataFrame(output_sequence)    # output_sequence.to_csv(save_Path + file_name + '_detect-sequence.csv')    # point_sequence = nms_point(segment_length, output_sequence)    point_sequence = pd.DataFrame(output_sequence)    point_sequence.to_csv(save_Path + str(signal_Channel) + '/' + file_name + '_points-location.csv', index=False)    print(str(file_name) + " detect and save complete ! ")    return point_sequence# NMS get the QRS wave pointdef nms_point(segment_length, output_sequence):    # output_sequence = pd.read_csv(save_Path + file_name + '_detect-sequence.csv')    output_sequence = np.array(output_sequence)    # because of only two classes, so if greater than 50%, it can be judged    output_sequence[output_sequence[:] < 0.5] = 0    point_sequence = []    sequence_list = output_sequence[:]    # print(len(sequence_list))    detect_num = math.floor(len(sequence_list) / segment_length)    # print(detect_num)    for loop_i in range(detect_num):        sequence_segment = sequence_list[loop_i * segment_length:(loop_i + 1) * segment_length]        # if loop_i < 10:        #     print(sequence_segment.shape)        if np.max(sequence_segment) > 0:            # print(np.argmax(sequence_segment))            detect_point = np.argmax(sequence_segment) + loop_i * segment_length            # print(detect_point)            point_sequence.append(detect_point)            pass        else:            pass        pass    pass    # print(point_sequence)    # there is a interval between contiguous heart-beat    sequence_copy = point_sequence.copy()    cut_num = 0    for loop_j in range(len(point_sequence) - 1):        pre_point = sequence_copy[loop_j + 1]        current_point = sequence_copy[loop_j]        if pre_point - current_point < segment_length:            if sequence_list[pre_point] >= sequence_list[current_point]:                point_sequence.pop(loop_j - cut_num)                pass            else:                point_sequence.pop(loop_j + 1 - cut_num)                pass            cut_num += 1            pass        pass    pass    # print(point_sequence)    return point_sequence# detect the heart-beat location and figuredef location_saver(model):    file_list = name_list(3, 3)    for file_name in file_list:        slide_detection(file_name, signal_Channel, model)        pass    print("\n detect process and save sequence complete ! \n")# calculate error between output point and signal annotations and figuredef point_and_figure(file_name, signal_channel, segment_length):    point_sequence = pd.read_csv(save_Path + str(signal_Channel) + '/' + file_name + '_points-location.csv')    # print(point_sequence)    lens = [0] * 50    # print(lens)    point_sequence = list(point_sequence.values)    for _ in range(80):        point_sequence.insert(400, 0)    # print(point_sequence)    # remove abnormal heart beat id    # figure a segment with detect points and annotations    start_find, end_find, start_index, end_index = 0, 1000, 0, 1100    # print(len(anns_id), len(point_sequence))    # anns_segment = anns_id[start_index:end_index]    point_segment = point_sequence[start_index:end_index]    # anns_segment = segment_start <= anns_id < segment_end    # point_segment = segment_start <= point_sequence < segment_end    plt.figure()    plt.plot(point_segment)    plt.title("ventricular signal")    # for index in anns_segment:    #     anns_index = index - segment_start    #     plt.scatter(x=anns_index, y=signal_segment[anns_index], marker="*")    plt.show()def signal_judgement(signal_channel, dataset_lead):    if signal_channel == 'lead0':        signal_lead = dataset_lead['lead0']        pass    elif signal_channel == 'lead1':        signal_lead = dataset_lead['lead1']        pass    elif signal_channel == 'lead2':        signal_lead = dataset_lead['lead2']        pass    elif signal_channel == 'lead3':        signal_lead = dataset_lead['lead3']        pass    else:        print("\n signal_channel error !")        sys.exit()        pass    return signal_lead# calculate error between output point and signal annotations and figuredef figure_fecg():    signal_sequence = pd.read_csv('/Users/collcertaye/WorkSpace/Lab-FECG/FECG_2020DB' + '/fecg04' + '.csv')    # print(point_sequence)    signal_sequence = list(signal_sequence.values)    # figure a segment with detect points and annotations    start_find, end_find, start_index, end_index = 0, 1000, 350, 1300    # print(len(anns_id), len(point_sequence))    signal_sequence = torch.Tensor(signal_sequence)    print(signal_sequence)    # anns_segment = anns_id[start_index:end_index]    signal_sequence = signal_sequence[start_index:end_index, 2]    # anns_segment = segment_start <= anns_id < segment_end    # point_segment = segment_start <= point_sequence < segment_end    plt.figure()    plt.plot(signal_sequence, color='purple')    plt.title("ventricular signal")    # for index in anns_segment:    #     anns_index = index - segment_start    #     plt.scatter(x=anns_index, y=signal_segment[anns_index], marker="*")    plt.show()input_Size, hidden_Size, output_Size = 1, 100, 2epoch_Num1, epoch_Num2, learning_Rate, sample_Frequency, segment_Length = 10, 10, 0.01, 1000, 320num_Channels = [96, 256, 384, 256]signal_Channel = 'lead0'cnnModel = UdAlexCnnModel(output_size=output_Size)lstmModel = LstmModel(input_size=input_Size, hidden_size=hidden_Size,                      output_size=output_Size)resModel = UdResNetModel(residual_block=ResidualBlock, output_size=output_Size)optimizer = optim.Adam(cnnModel.parameters(), lr=learning_Rate)criterion = nn.CrossEntropyLoss()time_start = time.time()print(time_start)# save_all_file()time_end = time.time()print(time_end - time_start)train_Loss, val_Loss, test_Loss, optim_Model = trainer_and_test(cnnModel, epoch_Num1)location_saver(optim_Model)# point_and_figure('a03', signal_Channel, segment_Length)figure_fecg()# point_and_figure('a03', signal_Channel, segment_Length)BiLstmModel = LstmModel(input_size=input_Size, hidden_size=hidden_Size, output_size=output_Size, bidirection=True)train_Loss2, val_Loss2, test_Loss2, optim_Model = trainer_and_test(lstmModel, epoch_Num2)location_saver(optim_Model)